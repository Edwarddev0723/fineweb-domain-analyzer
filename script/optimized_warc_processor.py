import gzip
import json
import re
import html
import opencc
from urllib.parse import urlparse
import os

class OptimizedChineseProcessor:
    def __init__(self):
        # åˆå§‹åŒ–è½¬æ¢å™¨
        self.converter_s2t = opencc.OpenCC('s2t')
        self.converter_t2s = opencc.OpenCC('t2s') 
        
        # ä¸¥æ ¼çš„æˆäººå†…å®¹è¿‡æ»¤
        self.inappropriate_keywords = [
            'AV', 'åšçˆ±', 'æ“é€¼', 'è‰²æƒ…', 'è£¸ä½“', 'æ€§çˆ±', 'ä¸‰çº§', 'porn', 'sex',
            'æ— ç ', 'æœ‰ç ', 'æˆäºº', 'æƒ…è‰²', 'æ¿€æƒ…', 'æ·«', 'éªš', 'çˆ½', '18+',
            'èµŒ', 'åšå½©', 'èµŒåœº', 'æŠ•æ³¨', 'ä¸‹æ³¨'
        ]
        
        # ç®€åŒ–çš„å¯¼èˆªæ£€æµ‹
        self.heavy_navigation_keywords = [
            'æœç´¢ç»“æœ', 'äº§å“å¤§å…¨', 'å…¨éƒ¨åˆ†ç±»', 'è´­ç‰©è½¦', 'ç«‹å³è´­ä¹°', 'å…è´¹è¯•ç”¨',
            'é©¬ä¸Šæ³¨å†Œ', 'ç‚¹å‡»æŸ¥çœ‹', 'ç›¸å…³æ¨è', 'çƒ­é—¨æ¨è', 'æœ€æ–°æ›´æ–°'
        ]
        
    def clean_text(self, text):
        """åŸºç¡€æ–‡æœ¬æ¸…ç†"""
        # HTMLå®ä½“è§£ç 
        text = html.unescape(text)
        
        # ç§»é™¤HTMLæ ‡ç­¾æ®‹ç•™
        text = re.sub(r'<[^>]+>', '', text)
        
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        text = re.sub(r'\s+', ' ', text)
        
        # ç§»é™¤ç‰¹æ®Šç¬¦å·åƒåœ¾
        text = re.sub(r'[^\u4e00-\u9fff\u3000-\u303f\uFF00-\uFFEF\w\s.,;:!?(){}[\]"""''â€”\-]', '', text)
        
        return text.strip()
    
    def detect_language_interference(self, text):
        """æ£€æµ‹ä¸¥é‡çš„è¯­è¨€å¹²æ‰°"""
        # åªæ£€æµ‹ä¸¥é‡å¹²æ‰°
        japanese_count = len(re.findall(r'[\u3040-\u309f\u30a0-\u30ff]', text))
        korean_count = len(re.findall(r'[\uac00-\ud7af]', text))
        
        japanese_ratio = japanese_count / len(text) if text else 0
        korean_ratio = korean_count / len(text) if text else 0
        
        # åªæœ‰å½“å¹²æ‰°æ¯”ä¾‹å¾ˆé«˜æ—¶æ‰æ‹’ç»
        has_severe_interference = japanese_ratio > 0.1 or korean_ratio > 0.1
        
        return {
            'japanese_ratio': japanese_ratio,
            'korean_ratio': korean_ratio,
            'has_severe_interference': has_severe_interference
        }
    
    def is_traditional_chinese(self, text, min_ratio=0.15):
        """æ”¾å®½çš„ç¹ä½“ä¸­æ–‡åˆ¤æ–­æ ‡å‡†"""
        if not text or len(text) < 30:  # é™ä½æœ€å°é•¿åº¦è¦æ±‚
            return False, 0, {}
        
        # æ¸…ç†æ–‡æœ¬
        cleaned_text = self.clean_text(text)
        
        # æ£€æŸ¥ä¸¥é‡ä¸é€‚å®œå†…å®¹
        text_lower = cleaned_text.lower()
        inappropriate_count = sum(1 for keyword in self.inappropriate_keywords if keyword in text_lower)
        if inappropriate_count >= 2:  # åªæœ‰åŒ…å«å¤šä¸ªä¸å½“è¯æ±‡æ‰æ‹’ç»
            return False, 0, {'inappropriate_content': True}
        
        # æ£€æŸ¥æ˜¯å¦ä¸»è¦æ˜¯å¯¼èˆªå†…å®¹ï¼ˆæ›´ä¸¥æ ¼çš„æ ‡å‡†ï¼‰
        nav_count = sum(1 for keyword in self.heavy_navigation_keywords if keyword in cleaned_text)
        if nav_count >= 3 and len(cleaned_text) < 200:  # çŸ­æ–‡æœ¬ä¸”å¤§é‡å¯¼èˆª
            return False, 0, {'heavy_navigation': True}
        
        # æ£€æŸ¥ä¸¥é‡è¯­è¨€å¹²æ‰°
        interference = self.detect_language_interference(cleaned_text)
        if interference['has_severe_interference']:
            return False, 0, interference
        
        # è®¡ç®—ä¸­æ–‡å­—ç¬¦æ¯”ä¾‹ï¼ˆæ”¾å®½æ ‡å‡†ï¼‰
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', cleaned_text))
        chinese_ratio = chinese_chars / len(cleaned_text) if cleaned_text else 0
        
        # ä¸­æ–‡å­—ç¬¦æ¯”ä¾‹è¦æ±‚é™ä½
        if chinese_ratio < 0.2:
            return False, 0, {'low_chinese_ratio': chinese_ratio}
        
        # è½¬æ¢æµ‹è¯•
        simplified = self.converter_t2s.convert(cleaned_text)
        traditional = self.converter_s2t.convert(cleaned_text)
        
        # è®¡ç®—å·®å¼‚
        diff_from_simplified = sum(1 for a, b in zip(cleaned_text, simplified) if a != b)
        diff_from_traditional = sum(1 for a, b in zip(cleaned_text, traditional) if a != b)
        
        # è®¡ç®—ç¹ä½“å­—æ¯”ä¾‹
        traditional_ratio = diff_from_simplified / len(cleaned_text) if cleaned_text else 0
        
        # æ›´çµæ´»çš„åˆ¤æ–­æ ‡å‡†
        is_traditional = (
            traditional_ratio >= min_ratio and  # é™ä½ç¹ä½“å­—æ¯”ä¾‹è¦æ±‚
            diff_from_simplified >= diff_from_traditional and  # æ›´æ¥è¿‘ç¹ä½“
            chinese_ratio >= 0.2  # é™ä½ä¸­æ–‡å­—ç¬¦æ¯”ä¾‹è¦æ±‚
        )
        
        confidence_score = min(1.0, traditional_ratio * 1.5 + chinese_ratio * 0.8)
        
        analysis = {
            'chinese_ratio': chinese_ratio,
            'traditional_ratio': traditional_ratio,
            'confidence_score': confidence_score,
            'diff_from_simplified': diff_from_simplified,
            'diff_from_traditional': diff_from_traditional,
            **interference
        }
        
        return is_traditional, traditional_ratio, analysis

    def process_warc_file(self, input_file, output_file, min_ratio=0.15, target_count=200):
        """å¤„ç†WARCæ–‡ä»¶ï¼Œä½¿ç”¨ä¼˜åŒ–çš„æ ‡å‡†"""
        print(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {input_file}")
        print(f"æœ€å°ç¹ä½“å­—æ¯”ä¾‹: {min_ratio}")
        print(f"ç›®æ ‡æ•°é‡: {target_count}")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        processed_count = 0
        saved_count = 0
        quality_stats = {
            'total': 0,
            'inappropriate_content': 0,
            'heavy_navigation': 0,
            'severe_interference': 0,
            'low_chinese_ratio': 0,
            'low_traditional_ratio': 0,
            'high_quality': 0
        }
        
        with gzip.open(input_file, 'rt', encoding='utf-8', errors='ignore') as f:
            with open(output_file, 'w', encoding='utf-8') as out_f:
                current_record = {}
                in_content = False
                content_lines = []
                
                for line in f:
                    line = line.strip()
                    
                    # æ–°è®°å½•å¼€å§‹
                    if line.startswith('WARC-Type:'):
                        # å¤„ç†å‰ä¸€ä¸ªè®°å½•
                        if current_record and in_content and content_lines:
                            processed_count += 1
                            quality_stats['total'] += 1
                            
                            # åˆå¹¶å†…å®¹ï¼Œé™åˆ¶é•¿åº¦ä»¥æé«˜å¤„ç†é€Ÿåº¦
                            content = '\n'.join(content_lines[:100])  # åªå–å‰100è¡Œ
                            content = self.clean_text(content)
                            
                            if len(content) >= 50:  # é™ä½æœ€å°é•¿åº¦è¦æ±‚
                                # æ£€æŸ¥æ˜¯å¦ä¸ºä¼˜è´¨ç¹ä½“ä¸­æ–‡
                                is_traditional, trad_ratio, analysis = self.is_traditional_chinese(content, min_ratio)
                                
                                # è®°å½•ç»Ÿè®¡ä¿¡æ¯
                                if analysis.get('inappropriate_content'):
                                    quality_stats['inappropriate_content'] += 1
                                elif analysis.get('heavy_navigation'):
                                    quality_stats['heavy_navigation'] += 1
                                elif analysis.get('has_severe_interference'):
                                    quality_stats['severe_interference'] += 1
                                elif analysis.get('low_chinese_ratio', 1) < 0.2:
                                    quality_stats['low_chinese_ratio'] += 1
                                elif trad_ratio < min_ratio:
                                    quality_stats['low_traditional_ratio'] += 1
                                
                                # å¦‚æœé€šè¿‡è´¨é‡æ£€æŸ¥
                                if is_traditional:
                                    quality_stats['high_quality'] += 1
                                    saved_count += 1
                                    
                                    # æ„å»ºè¾“å‡ºè®°å½•
                                    output_record = {
                                        'id': current_record.get('id', f'record_{processed_count}'),
                                        'url': current_record.get('url', ''),
                                        'text': content,
                                        'text_length': len(content),
                                        'traditional_ratio': trad_ratio,
                                        'confidence_score': analysis['confidence_score'],
                                        'chinese_ratio': analysis['chinese_ratio'],
                                        'is_traditional_chinese': True,
                                        'source_file': os.path.basename(input_file)
                                    }
                                    
                                    out_f.write(json.dumps(output_record, ensure_ascii=False) + '\n')
                                    out_f.flush()
                                    
                                    if saved_count % 5 == 0:
                                        print(f"å·²ä¿å­˜ {saved_count} æ¡ä¼˜è´¨ç¹ä½“ä¸­æ–‡è®°å½•")
                                    
                                    # è¾¾åˆ°ç›®æ ‡æ•°é‡åˆ™åœæ­¢
                                    if saved_count >= target_count:
                                        print(f"å·²è¾¾åˆ°ç›®æ ‡æ•°é‡ {target_count}ï¼Œåœæ­¢å¤„ç†")
                                        break
                        
                        # é‡ç½®çŠ¶æ€
                        current_record = {}
                        in_content = False
                        content_lines = []
                        
                        if processed_count % 2000 == 0:
                            print(f"å·²å¤„ç† {processed_count} æ¡è®°å½•ï¼Œå·²ä¿å­˜ {saved_count} æ¡ä¼˜è´¨è®°å½•")
                    
                    # è®°å½•URL
                    elif line.startswith('WARC-Target-URI:'):
                        current_record['url'] = line.split(':', 1)[1].strip()
                    
                    # è®°å½•ID
                    elif line.startswith('WARC-Record-ID:'):
                        warc_id = line.split(':', 1)[1].strip()
                        current_record['id'] = f"{os.path.basename(input_file)}_{abs(hash(warc_id)) % 10000}"
                    
                    # å†…å®¹å¼€å§‹
                    elif line == '' and current_record.get('url'):
                        in_content = True
                    
                    # æ”¶é›†å†…å®¹ï¼ˆé™åˆ¶è¡Œæ•°ï¼‰
                    elif in_content and line and len(content_lines) < 100:
                        content_lines.append(line)
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        print("\n" + "="*60)
        print("å¤„ç†å®Œæˆï¼ç»Ÿè®¡ä¿¡æ¯:")
        print(f"æ€»å…±å¤„ç†è®°å½•: {quality_stats['total']}")
        print(f"ä¿å­˜ä¼˜è´¨è®°å½•: {quality_stats['high_quality']}")
        print(f"è¿‡æ»¤åŸå› ç»Ÿè®¡:")
        print(f"  - ä¸é€‚å®œå†…å®¹: {quality_stats['inappropriate_content']}")
        print(f"  - é‡åº¦å¯¼èˆªå†…å®¹: {quality_stats['heavy_navigation']}")
        print(f"  - ä¸¥é‡è¯­è¨€å¹²æ‰°: {quality_stats['severe_interference']}")
        print(f"  - ä¸­æ–‡æ¯”ä¾‹è¿‡ä½: {quality_stats['low_chinese_ratio']}")
        print(f"  - ç¹ä½“å­—æ¯”ä¾‹è¿‡ä½: {quality_stats['low_traditional_ratio']}")
        if quality_stats['total'] > 0:
            print(f"è´¨é‡é€šè¿‡ç‡: {quality_stats['high_quality']/quality_stats['total']*100:.2f}%")
        print("="*60)
        
        return saved_count

def main():
    processor = OptimizedChineseProcessor()
    
    input_file = "fineweb-zhtw/data/WARC/CC-MAIN-2024-26/CC-MAIN-20240612140424-20240612170424-00001.warc.gz"
    output_file = "fineweb-zhtw/data/output_high_quality/optimized_traditional_chinese_CC-MAIN-20240612140424-20240612170424-00001.warc.jsonl"
    
    # ä½¿ç”¨æ›´å®½æ¾ä½†ä»æœ‰è´¨é‡ä¿è¯çš„æ ‡å‡†
    saved_count = processor.process_warc_file(
        input_file=input_file,
        output_file=output_file,
        min_ratio=0.15,  # é™ä½æœ€å°ç¹ä½“å­—æ¯”ä¾‹åˆ°15%
        target_count=200  # ç›®æ ‡200æ¡è®°å½•
    )
    
    print(f"\nâœ… æˆåŠŸæå– {saved_count} æ¡ä¼˜è´¨ç¹ä½“ä¸­æ–‡å†…å®¹")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")

if __name__ == "__main__":
    main()
