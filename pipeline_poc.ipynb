{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdf64cba",
   "metadata": {},
   "source": [
    "# URL域名提取和JSON整理工具\n",
    "\n",
    "此notebook用於從WARC/JSONL數據中提取唯一域名並整理成JSON格式，方便後續分析和使用。\n",
    "\n",
    "## 功能特點\n",
    "- 從URL中提取完整域名\n",
    "- 統計每個域名的出現頻次\n",
    "- 生成結構化的JSON輸出\n",
    "- 支持多種輸出格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "587ae8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 已導入所需庫\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "from collections import Counter, defaultdict\n",
    "import os\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "print(\"📚 已導入所需庫\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "754faf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 開始加載數據文件...\n",
      "加載文件: output_all\\extracted_content_CC-MAIN-20240612140424-20240612170424-00000.warc.jsonl\n",
      "  └─ 成功加載 3184 條記錄\n",
      "加載文件: fineweb-zhtw\\data\\output_high_quality\\clean_traditional_chinese.jsonl\n",
      "  └─ 成功加載 8 條記錄\n",
      "\n",
      "✅ 總共加載了 3192 條記錄\n"
     ]
    }
   ],
   "source": [
    "# 數據加載函數\n",
    "def load_jsonl_data(file_path):\n",
    "    \"\"\"從JSONL文件加載數據\"\"\"\n",
    "    data = []\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line_num, line in enumerate(f, 1):\n",
    "                if line.strip():\n",
    "                    try:\n",
    "                        data.append(json.loads(line))\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"第{line_num}行JSON解析錯誤: {e}\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"文件未找到: {file_path}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"讀取文件時出錯: {e}\")\n",
    "        return []\n",
    "\n",
    "# 指定數據文件路径\n",
    "data_files = [\n",
    "    r\"output_all\\extracted_content_CC-MAIN-20240612140424-20240612170424-00000.warc.jsonl\",\n",
    "    r\"fineweb-zhtw\\data\\output_high_quality\\clean_traditional_chinese.jsonl\"\n",
    "]\n",
    "\n",
    "print(\"🔍 開始加載數據文件...\")\n",
    "\n",
    "all_data = []\n",
    "for file_path in data_files:\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"加載文件: {file_path}\")\n",
    "        file_data = load_jsonl_data(file_path)\n",
    "        print(f\"  └─ 成功加載 {len(file_data)} 條記錄\")\n",
    "        all_data.extend(file_data)\n",
    "    else:\n",
    "        print(f\"文件不存在: {file_path}\")\n",
    "\n",
    "print(f\"\\n✅ 總共加載了 {len(all_data)} 條記錄\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4349277b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 開始處理URL並提取域名...\n",
      "  處理進度: 0/3192 (0.0%)\n",
      "  處理進度: 1000/3192 (31.3%)\n",
      "  處理進度: 2000/3192 (62.7%)\n",
      "  處理進度: 3000/3192 (94.0%)\n",
      "✅ 處理完成！共處理 3192 個URL\n",
      "📊 發現 2954 個唯一域名\n"
     ]
    }
   ],
   "source": [
    "# 域名提取和處理類\n",
    "class DomainExtractor:\n",
    "    \"\"\"智能域名提取器\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.domain_stats = defaultdict(lambda: {\n",
    "            'count': 0,\n",
    "            'urls': [],\n",
    "            'tld': '',\n",
    "            'subdomain_count': 0,\n",
    "            'first_seen': None,\n",
    "            'last_seen': None\n",
    "        })\n",
    "    \n",
    "    def extract_domain(self, url):\n",
    "        \"\"\"從URL提取域名\"\"\"\n",
    "        try:\n",
    "            parsed = urlparse(url)\n",
    "            domain = parsed.netloc.lower()\n",
    "            \n",
    "            # 移除端口號\n",
    "            if ':' in domain:\n",
    "                domain = domain.split(':')[0]\n",
    "            \n",
    "            # 移除www前綴（可選）\n",
    "            if domain.startswith('www.'):\n",
    "                domain = domain[4:]\n",
    "            \n",
    "            return domain\n",
    "        except Exception as e:\n",
    "            print(f\"URL解析錯誤 {url}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def extract_tld(self, domain):\n",
    "        \"\"\"提取頂級域名\"\"\"\n",
    "        if not domain or '.' not in domain:\n",
    "            return ''\n",
    "        return domain.split('.')[-1]\n",
    "    \n",
    "    def count_subdomains(self, domain):\n",
    "        \"\"\"計算子域名數量\"\"\"\n",
    "        if not domain:\n",
    "            return 0\n",
    "        return domain.count('.')\n",
    "    \n",
    "    def process_urls(self, data):\n",
    "        \"\"\"處理所有URL並提取域名信息\"\"\"\n",
    "        print(\"🔄 開始處理URL並提取域名...\")\n",
    "        \n",
    "        processed_count = 0\n",
    "        for i, record in enumerate(data):\n",
    "            if i % 1000 == 0:\n",
    "                print(f\"  處理進度: {i}/{len(data)} ({i/len(data)*100:.1f}%)\")\n",
    "            \n",
    "            url = record.get('url', '')\n",
    "            if not url:\n",
    "                continue\n",
    "            \n",
    "            domain = self.extract_domain(url)\n",
    "            if not domain:\n",
    "                continue\n",
    "            \n",
    "            # 更新域名統計\n",
    "            stats = self.domain_stats[domain]\n",
    "            stats['count'] += 1\n",
    "            stats['tld'] = self.extract_tld(domain)\n",
    "            stats['subdomain_count'] = self.count_subdomains(domain)\n",
    "            \n",
    "            # 記錄URL示例（最多保存5個）\n",
    "            if len(stats['urls']) < 5:\n",
    "                stats['urls'].append(url)\n",
    "            \n",
    "            # 記錄時間戳（如果有的話）\n",
    "            timestamp = record.get('timestamp') or record.get('date') or datetime.now().isoformat()\n",
    "            if stats['first_seen'] is None:\n",
    "                stats['first_seen'] = timestamp\n",
    "            stats['last_seen'] = timestamp\n",
    "            \n",
    "            processed_count += 1\n",
    "        \n",
    "        print(f\"✅ 處理完成！共處理 {processed_count} 個URL\")\n",
    "        print(f\"📊 發現 {len(self.domain_stats)} 個唯一域名\")\n",
    "        \n",
    "        return self.domain_stats\n",
    "\n",
    "# 初始化域名提取器\n",
    "extractor = DomainExtractor()\n",
    "\n",
    "# 處理數據\n",
    "if all_data:\n",
    "    domain_data = extractor.process_urls(all_data)\n",
    "else:\n",
    "    print(\"⚠️ 沒有數據可處理\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "842fbf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 開始生成JSON輸出...\n",
      "\n",
      "📊 域名統計摘要:\n",
      "  唯一域名總數: 2,954\n",
      "\n",
      "🏆 前10個最頻繁域名:\n",
      "   1. cujasweb.univ-paris1.fr: 5 次\n",
      "   2. licitacoeseb.9rm.eb.mil.br: 4 次\n",
      "   3. luna.library.cmu.edu: 4 次\n",
      "   4. siganus.php.xdomain.jp: 4 次\n",
      "   5. imagemagick.org: 4 次\n",
      "   6. business.kanerepublican.com: 3 次\n",
      "   7. collections.artmuseum.utoronto.ca: 3 次\n",
      "   8. forum.artofwar.net.ru: 3 次\n",
      "   9. ftp.cpan.org: 3 次\n",
      "  10. ftp.mozilla.org: 3 次\n",
      "\n",
      "🌐 頂級域名分布 (前5):\n",
      "  .com: 1421 個域名\n",
      "  .ru: 185 個域名\n",
      "  .org: 138 個域名\n",
      "  .net: 135 個域名\n",
      "  .cn: 113 個域名\n",
      "\n",
      "💾 正在保存JSON文件...\n",
      "💾 已保存: domain_extracts\\simple_list_20250717_162329.json\n",
      "💾 已保存: domain_extracts\\detailed_stats_20250717_162329.json\n",
      "💾 已保存: domain_extracts\\frequency_ranked_20250717_162329.json\n",
      "💾 已保存: domain_extracts\\tld_grouped_20250717_162329.json\n",
      "\n",
      "✅ 完成！共生成 4 個JSON文件\n"
     ]
    }
   ],
   "source": [
    "# JSON輸出生成器\n",
    "class JSONOutputGenerator:\n",
    "    \"\"\"生成多種格式的JSON輸出\"\"\"\n",
    "    \n",
    "    def __init__(self, domain_data):\n",
    "        self.domain_data = domain_data\n",
    "        self.timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    def generate_simple_list(self):\n",
    "        \"\"\"生成簡單的域名列表\"\"\"\n",
    "        domains = list(self.domain_data.keys())\n",
    "        domains.sort()\n",
    "        return {\n",
    "            \"metadata\": {\n",
    "                \"generated_at\": datetime.now().isoformat(),\n",
    "                \"total_domains\": len(domains),\n",
    "                \"format\": \"simple_list\"\n",
    "            },\n",
    "            \"domains\": domains\n",
    "        }\n",
    "    \n",
    "    def generate_detailed_stats(self):\n",
    "        \"\"\"生成詳細的域名統計信息\"\"\"\n",
    "        detailed_data = {}\n",
    "        \n",
    "        for domain, stats in self.domain_data.items():\n",
    "            detailed_data[domain] = {\n",
    "                \"count\": stats['count'],\n",
    "                \"tld\": stats['tld'],\n",
    "                \"subdomain_count\": stats['subdomain_count'],\n",
    "                \"sample_urls\": stats['urls'],\n",
    "                \"first_seen\": stats['first_seen'],\n",
    "                \"last_seen\": stats['last_seen']\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"metadata\": {\n",
    "                \"generated_at\": datetime.now().isoformat(),\n",
    "                \"total_domains\": len(detailed_data),\n",
    "                \"total_urls_processed\": sum(stats['count'] for stats in self.domain_data.values()),\n",
    "                \"format\": \"detailed_stats\"\n",
    "            },\n",
    "            \"domains\": detailed_data\n",
    "        }\n",
    "    \n",
    "    def generate_frequency_ranked(self):\n",
    "        \"\"\"生成按頻率排序的域名列表\"\"\"\n",
    "        sorted_domains = sorted(\n",
    "            self.domain_data.items(), \n",
    "            key=lambda x: x[1]['count'], \n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        ranked_list = []\n",
    "        for rank, (domain, stats) in enumerate(sorted_domains, 1):\n",
    "            ranked_list.append({\n",
    "                \"rank\": rank,\n",
    "                \"domain\": domain,\n",
    "                \"count\": stats['count'],\n",
    "                \"percentage\": round(stats['count'] / sum(s['count'] for s in self.domain_data.values()) * 100, 2),\n",
    "                \"tld\": stats['tld']\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            \"metadata\": {\n",
    "                \"generated_at\": datetime.now().isoformat(),\n",
    "                \"total_domains\": len(ranked_list),\n",
    "                \"ranking_criteria\": \"url_frequency\",\n",
    "                \"format\": \"frequency_ranked\"\n",
    "            },\n",
    "            \"domains\": ranked_list\n",
    "        }\n",
    "    \n",
    "    def generate_tld_grouped(self):\n",
    "        \"\"\"按頂級域名分組的域名列表\"\"\"\n",
    "        tld_groups = defaultdict(list)\n",
    "        \n",
    "        for domain, stats in self.domain_data.items():\n",
    "            tld = stats['tld'] or 'no_tld'\n",
    "            tld_groups[tld].append({\n",
    "                \"domain\": domain,\n",
    "                \"count\": stats['count']\n",
    "            })\n",
    "        \n",
    "        # 對每個TLD組內的域名按頻率排序\n",
    "        for tld in tld_groups:\n",
    "            tld_groups[tld].sort(key=lambda x: x['count'], reverse=True)\n",
    "        \n",
    "        return {\n",
    "            \"metadata\": {\n",
    "                \"generated_at\": datetime.now().isoformat(),\n",
    "                \"total_domains\": len(self.domain_data),\n",
    "                \"total_tlds\": len(tld_groups),\n",
    "                \"format\": \"tld_grouped\"\n",
    "            },\n",
    "            \"tld_groups\": dict(tld_groups)\n",
    "        }\n",
    "    \n",
    "    def save_all_formats(self, output_dir=\"domain_extracts\"):\n",
    "        \"\"\"保存所有格式的JSON文件\"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        formats = {\n",
    "            \"simple_list\": self.generate_simple_list(),\n",
    "            \"detailed_stats\": self.generate_detailed_stats(),\n",
    "            \"frequency_ranked\": self.generate_frequency_ranked(),\n",
    "            \"tld_grouped\": self.generate_tld_grouped()\n",
    "        }\n",
    "        \n",
    "        saved_files = []\n",
    "        for format_name, data in formats.items():\n",
    "            filename = f\"{format_name}_{self.timestamp}.json\"\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            \n",
    "            with open(filepath, 'w', encoding='utf-8') as f:\n",
    "                json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            saved_files.append(filepath)\n",
    "            print(f\"💾 已保存: {filepath}\")\n",
    "        \n",
    "        return saved_files\n",
    "\n",
    "# 生成JSON輸出\n",
    "if 'domain_data' in locals() and domain_data:\n",
    "    print(\"📄 開始生成JSON輸出...\")\n",
    "    \n",
    "    generator = JSONOutputGenerator(domain_data)\n",
    "    \n",
    "    # 顯示統計摘要\n",
    "    print(f\"\\n📊 域名統計摘要:\")\n",
    "    print(f\"  唯一域名總數: {len(domain_data):,}\")\n",
    "    \n",
    "    # 按頻率顯示前10個域名\n",
    "    top_domains = sorted(domain_data.items(), key=lambda x: x[1]['count'], reverse=True)[:10]\n",
    "    print(f\"\\n🏆 前10個最頻繁域名:\")\n",
    "    for i, (domain, stats) in enumerate(top_domains, 1):\n",
    "        print(f\"  {i:2d}. {domain}: {stats['count']} 次\")\n",
    "    \n",
    "    # TLD統計\n",
    "    tld_counter = Counter(stats['tld'] for stats in domain_data.values())\n",
    "    print(f\"\\n🌐 頂級域名分布 (前5):\")\n",
    "    for tld, count in tld_counter.most_common(5):\n",
    "        print(f\"  .{tld}: {count} 個域名\")\n",
    "    \n",
    "    # 保存所有格式\n",
    "    print(f\"\\n💾 正在保存JSON文件...\")\n",
    "    saved_files = generator.save_all_formats()\n",
    "    \n",
    "    print(f\"\\n✅ 完成！共生成 {len(saved_files)} 個JSON文件\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ 沒有域名數據可生成JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "039e52c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 請先運行域名提取和JSON生成\n",
      "\n",
      "📁 生成的JSON文件用途說明:\n",
      "==================================================\n",
      "1️⃣  simple_list.json:\n",
      "   └─ 純域名列表，適合快速查看和導入其他工具\n",
      "2️⃣  detailed_stats.json:\n",
      "   └─ 完整統計信息，包含URL示例、出現次數等\n",
      "3️⃣  frequency_ranked.json:\n",
      "   └─ 按熱門程度排序，方便識別主要域名來源\n",
      "4️⃣  tld_grouped.json:\n",
      "   └─ 按網域類型分組，便於分析域名分布特徵\n",
      "\n",
      "💡 使用建議:\n",
      "  • 用於白名單/黑名單管理\n",
      "  • 域名信譽分析\n",
      "  • 數據來源追踪\n",
      "  • 版權風險評估\n",
      "  • 網站分類和過濾\n"
     ]
    }
   ],
   "source": [
    "# JSON數據預覽和驗證\n",
    "def preview_json_formats():\n",
    "    \"\"\"預覽不同格式的JSON結構\"\"\"\n",
    "    if 'generator' not in locals() or not domain_data:\n",
    "        print(\"⚠️ 請先運行域名提取和JSON生成\")\n",
    "        return\n",
    "    \n",
    "    print(\"🔍 JSON格式預覽:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. 簡單列表格式預覽\n",
    "    simple_data = generator.generate_simple_list()\n",
    "    print(\"📋 1. 簡單列表格式 (simple_list.json):\")\n",
    "    print(f\"  └─ 包含 {simple_data['metadata']['total_domains']} 個域名\")\n",
    "    print(\"  └─ 結構預覽:\")\n",
    "    preview_simple = {\n",
    "        \"metadata\": simple_data['metadata'],\n",
    "        \"domains\": simple_data['domains'][:3] + [\"...\"] if len(simple_data['domains']) > 3 else simple_data['domains']\n",
    "    }\n",
    "    print(json.dumps(preview_simple, ensure_ascii=False, indent=4))\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 50)\n",
    "    \n",
    "    # 2. 詳細統計格式預覽\n",
    "    detailed_data = generator.generate_detailed_stats()\n",
    "    print(\"📊 2. 詳細統計格式 (detailed_stats.json):\")\n",
    "    print(f\"  └─ 包含詳細統計信息\")\n",
    "    print(\"  └─ 結構預覽:\")\n",
    "    first_domain = list(detailed_data['domains'].keys())[0]\n",
    "    preview_detailed = {\n",
    "        \"metadata\": detailed_data['metadata'],\n",
    "        \"domains\": {\n",
    "            first_domain: detailed_data['domains'][first_domain],\n",
    "            \"...\": \"更多域名數據\"\n",
    "        }\n",
    "    }\n",
    "    print(json.dumps(preview_detailed, ensure_ascii=False, indent=4))\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 50)\n",
    "    \n",
    "    # 3. 頻率排序格式預覽\n",
    "    ranked_data = generator.generate_frequency_ranked()\n",
    "    print(\"🏆 3. 頻率排序格式 (frequency_ranked.json):\")\n",
    "    print(f\"  └─ 按URL出現頻率排序\")\n",
    "    print(\"  └─ 結構預覽:\")\n",
    "    preview_ranked = {\n",
    "        \"metadata\": ranked_data['metadata'],\n",
    "        \"domains\": ranked_data['domains'][:3] + [{\"...\": \"更多排序數據\"}] if len(ranked_data['domains']) > 3 else ranked_data['domains']\n",
    "    }\n",
    "    print(json.dumps(preview_ranked, ensure_ascii=False, indent=4))\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 50)\n",
    "    \n",
    "    # 4. TLD分組格式預覽\n",
    "    tld_data = generator.generate_tld_grouped()\n",
    "    print(\"🌐 4. TLD分組格式 (tld_grouped.json):\")\n",
    "    print(f\"  └─ 按頂級域名分組\")\n",
    "    print(\"  └─ 結構預覽:\")\n",
    "    first_tld = list(tld_data['tld_groups'].keys())[0]\n",
    "    preview_tld = {\n",
    "        \"metadata\": tld_data['metadata'],\n",
    "        \"tld_groups\": {\n",
    "            first_tld: tld_data['tld_groups'][first_tld][:2] + [{\"...\": \"更多域名\"}] if len(tld_data['tld_groups'][first_tld]) > 2 else tld_data['tld_groups'][first_tld],\n",
    "            \"...\": \"更多TLD分組\"\n",
    "        }\n",
    "    }\n",
    "    print(json.dumps(preview_tld, ensure_ascii=False, indent=4))\n",
    "\n",
    "# 運行預覽\n",
    "if 'domain_data' in locals() and domain_data:\n",
    "    preview_json_formats()\n",
    "    \n",
    "    print(f\"\\n📁 生成的JSON文件用途說明:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"1️⃣  simple_list.json:\")\n",
    "    print(\"   └─ 純域名列表，適合快速查看和導入其他工具\")\n",
    "    print(\"2️⃣  detailed_stats.json:\")\n",
    "    print(\"   └─ 完整統計信息，包含URL示例、出現次數等\")\n",
    "    print(\"3️⃣  frequency_ranked.json:\")\n",
    "    print(\"   └─ 按熱門程度排序，方便識別主要域名來源\")\n",
    "    print(\"4️⃣  tld_grouped.json:\")\n",
    "    print(\"   └─ 按網域類型分組，便於分析域名分布特徵\")\n",
    "    \n",
    "    print(f\"\\n💡 使用建議:\")\n",
    "    print(\"  • 用於白名單/黑名單管理\")\n",
    "    print(\"  • 域名信譽分析\") \n",
    "    print(\"  • 數據來源追踪\")\n",
    "    print(\"  • 版權風險評估\")\n",
    "    print(\"  • 網站分類和過濾\")\n",
    "\n",
    "else:\n",
    "    print(\"⚠️ 請先運行前面的數據加載和處理步驟\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sms_cluster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
